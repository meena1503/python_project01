import numpy as np
import pandas as pd

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

import seaborn as sns
import matplotlib.pyplot as plt

import os
import tkinter as tk
from tkinter import filedialog

class MalwareAnalysisApp:
    def __init__(self, master):
        self.master = master
        master.title("Malware Analysis")
        master.geometry("720x450")

        # Label and Textbox
        self.label_select_dataset = tk.Label(master, text="MALWARE ANALYSIS", font=("arial", 15))
        self.label_select_dataset.pack(pady=40)
       
        self.label_select_dataset = tk.Label(master, text="Select Dataset", font=("arial", 15))
        self.label_select_dataset.pack(pady=10)

        self.textbox_dataset_path = tk.Entry(master, width=50)
        self.textbox_dataset_path.pack(padx=50, pady=0)

        # Browse Button
        self.browse_button = tk.Button(master, text="Browse", font=("arial", 10), command=self.browse_dataset)
        self.browse_button.pack(pady=10)

        # Train and Predict Buttons
        self.train_button = tk.Button(master, text="Train", font=("arial", 10), command=self.train_model)
        self.train_button.place(x=0, y=100)
        self.train_button.pack(side=tk.LEFT, padx=150, pady=50)

        self.predict_button = tk.Button(master, text="Predict", font=("arial", 10), command=self.predict_data)
        self.predict_button.pack(side=tk.RIGHT, padx=150, pady=50)

        # Load the trained model
        self.rfc_model = None

    def browse_dataset(self):
        file_path = filedialog.askopenfilename(title="Select Dataset", filetypes=[("CSV Files", "*.csv")])
        self.textbox_dataset_path.delete(0, tk.END)
        self.textbox_dataset_path.insert(0, file_path)

    def train_model(self):
        dataset_path = self.textbox_dataset_path.get()
        if not dataset_path:
            print("Please select a dataset first.")
            return

        # Load the dataset
        try:
            dataset = pd.read_csv(dataset_path)
        except Exception as e:
            print(f"Error loading dataset: {e}")
            return

        # Drop unnecessary columns
        df = dataset.drop(columns=['hash'], axis=1)

        # Encode the target variable
        encoder = LabelEncoder()
        df['classification'] = encoder.fit_transform(df['classification'])

        # Remove columns with no correlation
        df_new = df.drop(columns=['usage_counter', 'normal_prio', 'policy', 'vm_pgoff', 'task_size',
                                  'cached_hole_size', 'hiwater_rss', 'nr_ptes', 'lock', 'cgtime',
                                  'signal_nvcsw'], axis=1)

        # Split the dataset into features and target
        X = df_new.drop(columns=['classification'], axis=1)
        y = df_new['classification']

        # Scale the features
        scaler = MinMaxScaler()
        X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

        # Split the dataset into training and test sets
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)

        # Initialize the Random Forest classifier
        self.rfc_model = RandomForestClassifier(n_estimators=50, max_depth=8)

        # Train the model
        self.rfc_model.fit(X_train, y_train)

        print("Model Trained Successfully.")

    def predict_data(self):
        if self.rfc_model is None:
            print("Please train the model first.")
            return

        # Load the dataset (you can reuse the code for loading and preprocessing from train_model() method)
        dataset_path = self.textbox_dataset_path.get()
        if not dataset_path:
            print("Please select a dataset first.")
            return

        try:
            dataset = pd.read_csv(dataset_path)
        except Exception as e:
            print(f"Error loading dataset: {e}")
            return

        # Drop unnecessary columns, encode the target variable, remove columns with no correlation, scale the features, etc.

        # Drop unnecessary columns
        df = dataset.drop(columns=['hash'], axis=1)

        # Encode the target variable
        encoder = LabelEncoder()
        df['classification'] = encoder.fit_transform(df['classification'])

        # Remove columns with no correlation
        df_new = df.drop(columns=['usage_counter', 'normal_prio', 'policy', 'vm_pgoff', 'task_size',
                                  'cached_hole_size', 'hiwater_rss', 'nr_ptes', 'lock', 'cgtime',
                                  'signal_nvcsw'], axis=1)

        # Split the dataset into features and target
        X = df_new.drop(columns=['classification'], axis=1)
        y = df_new['classification']

        scaler = MinMaxScaler()
        X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)
       
        # Make predictions
        rfc_model = RandomForestClassifier(n_estimators = 50, max_depth = 8)
        rfc_model.fit(X_train, y_train)
        rfc_xtest_pred = rfc_model.predict(X_test)
       
        y_pred = self.rfc_model.predict(X_test)

        # Evaluate predictions
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Model Accuracy: {accuracy * 100:.2f}%")

        # Display confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
        plt.xlabel('Actual Labels')
        plt.ylabel('Prediction Labels')
        plt.title('Confusion Matrix')
        plt.show()

        print(classification_report(y_test, rfc_xtest_pred))

if __name__ == "__main__":
    root = tk.Tk()
    app = MalwareAnalysisApp(root)
    root.mainloop()
